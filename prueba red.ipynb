{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0ca2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31778c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#              PROCEDIMIENTO DE MEDIDOR                 #              \n",
    "#########################################################\n",
    "#   1. Separar el Dataset entre entrenamiento y test    #\n",
    "#   2. Separar el Conjunto de entramiento en baseData   #\n",
    "#      y poolData (Basedata puede ser 50,100...)        #\n",
    "#   3. Calcular la distance entre las clases del        #\n",
    "#      baseData con la muestra que vamos añadiendo      #\n",
    "#   4. Calcular la distribución Softmax y la Entropía   #\n",
    "#   5. Añadir el ejemplo si es de buena calidad,        #\n",
    "#      podemos incluir el num de ejemplos que queramos  #\n",
    "#      por ejemplo añadir solo 10                       #\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medidorDistEntr(X,y,adi,n_base):\n",
    "    #---------1-----------#\n",
    "    X1,X_test,y1,y_test = train_test_split(X, y,stratify=y,test_size=0.2,random_state=42,shuffle=True)\n",
    "    #--------2------------#\n",
    "    # Para calcular el porcentaje de samples en la base (se calcula numero*numClases)\n",
    "    numClass= len(np.unique(y1)) #saber cuantas clases diferentes hay\n",
    "    numTotal = X1.shape[0]\n",
    "    porc = ((n_base*numClass*100)/numTotal)/100\n",
    "    print(porc)\n",
    "    X_Pool,X_Base,y_Pool,y_Base = train_test_split(X1, y1,stratify=y1,test_size=porc,random_state=42,shuffle=True)\n",
    "    #-------3------------#\n",
    "    centros=[]\n",
    "    val, cont = np.unique(y_Base,return_counts=True)\n",
    "    for i in val:\n",
    "        ind_i=np.where(y_Base==i)\n",
    "        suma = sum(X_Base[ind_i])\n",
    "        centro=suma/cont[i]\n",
    "        centros.append(centro)\n",
    "    #-------4-------------#\n",
    "    entropies = [entropy(softmax(listEuclidean(x,centros))) for x in X_Pool]\n",
    "    #listEuclidean devuelve una lista con la disctancia de un ejemplo con las clases del conjunto base\n",
    "    #-------5------------#\n",
    "    #Primero ordeno las entropias de mayor a menos\n",
    "    entroMaxs = sorted(entropies,reverse=True)[:adi] #adi se refiere al número de muestras que queremos añadir\n",
    "    in_add=[]\n",
    "    #Aquí busco que índices en el conjunto de datos son los que tienen la entropía mayor\n",
    "    for en in entroMaxs:\n",
    "        in_add.append(np.where(np.array(entropies) == en)[0][0]) #Para calcular los índices con mayor entropía\n",
    "        \n",
    "    X_adicionantes=X_Pool[in_add]\n",
    "    y_adicionantes=y_Pool[in_add]\n",
    "    #-----Finalmente añadimos al subconjunto base-----#\n",
    "    X_res = np.append(X_Base,X_adicionantes,axis=0)\n",
    "    y_res = np.append(y_Base,y_adicionantes)\n",
    "    \n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182369ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listEuclidean (p1,cen):\n",
    "    return [euclidean(p1,c) for c in cen]\n",
    "\n",
    "def euclidean (p1,p2):\n",
    "    res_e = (p2-p1)**2\n",
    "    suma = sum(res_e)\n",
    "    return math.sqrt(suma)\n",
    "\n",
    "def softmax(distances):\n",
    "    expon = np.exp(distances)\n",
    "    suma = np.sum(expon)\n",
    "    return expon/suma\n",
    "    \n",
    "def entropy(softProb):\n",
    "    op = softProb*(np.log2(softProb))\n",
    "    return -1*(np.sum(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7caea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion-mnist\\fashion-mnist_test.csv\n",
      "fashion-mnist\\fashion-mnist_train.csv\n",
      "fashion-mnist\\t10k-images-idx3-ubyte\n",
      "fashion-mnist\\t10k-labels-idx1-ubyte\n",
      "fashion-mnist\\train-images-idx3-ubyte\n",
      "fashion-mnist\\train-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "# Aqui voy a importar el data set fashion-mnist. \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('fashion-mnist'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "train = pd.read_csv('fashion-mnist/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('fashion-mnist/fashion-mnist_test.csv')\n",
    "\n",
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "\n",
    "X_train = df_train.drop(['label'],axis = 1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_test = df_test.drop(['label'],axis = 1)\n",
    "y_test = df_test['label']\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7740fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos en un numpy para poder tratarlos los datos mejor\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434dc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para la red vamos a usar una red convolucional con la siguiente estructura:\n",
    "def define_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "     # compile model\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "666e655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#            Medidor             #\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para una primera prueba, vamos a experimentar usando la técnica del medidor\n",
    "#para ello usamos la función descrita anteriormente.\n",
    "X_res,y_res = medidorDistEntr(X_train,y_train,4800,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos los datos en una matriz 28x28 para poder tratarlos en la red convolucional.\n",
    "X_res = X_res.reshape((X_res.shape[0], 28,28 ))\n",
    "X_test = X_test.reshape((X_test.shape[0],28,28))\n",
    "\n",
    "#Como la salida de la red va a ser softmax, tenemos que pasar los datos con una codificación one hot, \n",
    "#de manera que convierte una variable categórica en un vector binario en el que solo un elemento tiene \n",
    "#el valor 1 y todos los demás elementos tienen el valor 0\n",
    "y_res = to_categorical(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58be70a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 28, 28)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizamos las dimensiones de cada conjunto.\n",
    "print(X_res.shape)\n",
    "print(y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebc0f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68f4c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "338/338 [==============================] - 6s 16ms/step - loss: 0.7045 - accuracy: 0.7491 - val_loss: 0.5667 - val_accuracy: 0.7732\n",
      "Epoch 2/15\n",
      "338/338 [==============================] - 5s 16ms/step - loss: 0.4240 - accuracy: 0.8494 - val_loss: 0.4250 - val_accuracy: 0.8481\n",
      "Epoch 3/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.3442 - accuracy: 0.8803 - val_loss: 0.3526 - val_accuracy: 0.8711\n",
      "Epoch 4/15\n",
      "338/338 [==============================] - 6s 17ms/step - loss: 0.2887 - accuracy: 0.8958 - val_loss: 0.3637 - val_accuracy: 0.8642\n",
      "Epoch 5/15\n",
      "338/338 [==============================] - 6s 17ms/step - loss: 0.2449 - accuracy: 0.9105 - val_loss: 0.3269 - val_accuracy: 0.8827\n",
      "Epoch 6/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.2177 - accuracy: 0.9239 - val_loss: 0.3236 - val_accuracy: 0.8836\n",
      "Epoch 7/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.1843 - accuracy: 0.9368 - val_loss: 0.3745 - val_accuracy: 0.8761\n",
      "Epoch 8/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.1607 - accuracy: 0.9449 - val_loss: 0.3261 - val_accuracy: 0.8886\n",
      "Epoch 9/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.1443 - accuracy: 0.9510 - val_loss: 0.3059 - val_accuracy: 0.8943\n",
      "Epoch 10/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.1193 - accuracy: 0.9591 - val_loss: 0.3202 - val_accuracy: 0.8928\n",
      "Epoch 11/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.1031 - accuracy: 0.9668 - val_loss: 0.3286 - val_accuracy: 0.8957\n",
      "Epoch 12/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.0862 - accuracy: 0.9700 - val_loss: 0.3377 - val_accuracy: 0.8941\n",
      "Epoch 13/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 0.3342 - val_accuracy: 0.8977\n",
      "Epoch 14/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.3703 - val_accuracy: 0.8878\n",
      "Epoch 15/15\n",
      "338/338 [==============================] - 6s 18ms/step - loss: 0.0581 - accuracy: 0.9817 - val_loss: 0.4048 - val_accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo mientras observamos sus métricas.\n",
    "inicio=time.time()\n",
    "train = model.fit(X_res, y_res, epochs=15, batch_size=32,validation_data=(X_testf, y_testf))\n",
    "fin=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "79977e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.27051401138306"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculamos el tiempo que ha usado.\n",
    "fin-inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43089453",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#      Base          #\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8912295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para esta prueba vamos a analizar que ocurre cuando entrenamos la red con\n",
    "#un conjunto de datos pequeño que sería el equivalante al conjunto que se ha usado anteriormente\n",
    "#pero sin añadir ninguna de las muestras y transformamos de igual modo\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28,28 ))\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#También ara estudiar como afecta con diferentes cantidades de datos separándolas de manera estratificada \n",
    "#en esta sección del notebook se va a ir modificando el porcentaje en \"test_size\" de manera que se usará \n",
    "#un 10%, 25%, 30%, 40% y 50% del total de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6f592a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el conjunto inicial y coloco de tamaño de test un 92% para que en el entrenamiento\n",
    "# use solo 6000 datos \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e44f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cf4144fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "150/150 [==============================] - 3s 14ms/step - loss: 0.7903 - accuracy: 0.7096 - val_loss: 0.5547 - val_accuracy: 0.7975\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.5052 - accuracy: 0.8056 - val_loss: 0.4774 - val_accuracy: 0.8383\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4304 - accuracy: 0.8429 - val_loss: 0.4538 - val_accuracy: 0.8367\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.3761 - accuracy: 0.8629 - val_loss: 0.4130 - val_accuracy: 0.8617\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.3130 - accuracy: 0.8848 - val_loss: 0.3981 - val_accuracy: 0.8625\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.2853 - accuracy: 0.8990 - val_loss: 0.3880 - val_accuracy: 0.8625\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.2462 - accuracy: 0.9087 - val_loss: 0.3428 - val_accuracy: 0.8842\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.2256 - accuracy: 0.9187 - val_loss: 0.3677 - val_accuracy: 0.8792\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1967 - accuracy: 0.9333 - val_loss: 0.3742 - val_accuracy: 0.8775\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1779 - accuracy: 0.9340 - val_loss: 0.4177 - val_accuracy: 0.8642\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1625 - accuracy: 0.9450 - val_loss: 0.3886 - val_accuracy: 0.8642\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1346 - accuracy: 0.9529 - val_loss: 0.3593 - val_accuracy: 0.8942\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1326 - accuracy: 0.9517 - val_loss: 0.3957 - val_accuracy: 0.8717\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1076 - accuracy: 0.9640 - val_loss: 0.3796 - val_accuracy: 0.8783\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.0946 - accuracy: 0.9710 - val_loss: 0.4228 - val_accuracy: 0.8808\n"
     ]
    }
   ],
   "source": [
    "#entrenamos el modelo.\n",
    "inicio= time.time()\n",
    "train = model.fit(X_train, y_train, epochs=15, batch_size=32,validation_data=(X_test, y_test))\n",
    "fin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "18aa1d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.705026626586914"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculamos el tiempo.\n",
    "fin-inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "da7453fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#     COMPLETO     #\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ae6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalmente voy a estudiar el rendimiento del modelo usando todos \n",
    "#los datos que nos proporciona el dataset.\n",
    "\n",
    "#Para ello transformamos los datos como en las anteriores ocasiones\n",
    "X_train = X_train.reshape((X_train.shape[0], 28,28 ))\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d43491a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos para tener conjuto de test\n",
    "X_train_com, X_test_com, y_train_com, y_test_com = train_test_split(X_train, y_train, stratify=y_train, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6a5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8b5cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], 28,28 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4a49494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27c3106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.3030 - val_accuracy: 0.9217\n",
      "Epoch 2/15\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.3186 - val_accuracy: 0.9221\n",
      "Epoch 3/15\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 0.3272 - val_accuracy: 0.9183\n",
      "Epoch 4/15\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 0.3515 - val_accuracy: 0.9219\n",
      "Epoch 5/15\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.3507 - val_accuracy: 0.9216\n",
      "Epoch 6/15\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.3473 - val_accuracy: 0.9191\n",
      "Epoch 7/15\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.3613 - val_accuracy: 0.9208\n",
      "Epoch 8/15\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.3777 - val_accuracy: 0.9209\n",
      "Epoch 9/15\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.3814 - val_accuracy: 0.9216\n",
      "Epoch 10/15\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.3957 - val_accuracy: 0.9237\n",
      "Epoch 11/15\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.3989 - val_accuracy: 0.9219\n",
      "Epoch 12/15\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.3986 - val_accuracy: 0.9208\n",
      "Epoch 13/15\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 0.4161 - val_accuracy: 0.9220\n",
      "Epoch 14/15\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.4207 - val_accuracy: 0.9217\n",
      "Epoch 15/15\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.4257 - val_accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "#entrenamos\n",
    "inicio=time.time()\n",
    "train = model.fit(X_train, y_train, epochs=15, batch_size=64,validation_data=(X_test, y_test))\n",
    "fin=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4913721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405.6341555118561"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin-inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126104e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#                                        CNN                                     #\n",
    "##################################################################################\n",
    "#  porcentaje  #    10%    #    25%    #    30%    #   40%   #   50%   #   80%   #\n",
    "##################################################################################\n",
    "# Num muestras #    6000    #  15000   #   18000   #  24000  #  30000  #  48000  #\n",
    "# Precisión    #    0.87    #   0.89   #    0.90   #   0.90  #  0.90   #  0.92   #\n",
    "# Tiempo       #    57.01   #  112.87  #  137.33   # 165.90  #  205.81 # 318.88  #\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b5f8e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#                         CNN                        #\n",
    "######################################################\n",
    "#  Conjunto   #    prec    #   tiempo    #  Muestras #\n",
    "######################################################\n",
    "# Indicador   #    0.88    #   36.9167   # 6000 (5000 + 1000)   #\n",
    "# Estratifi   #    0.88    #   31.705    #    6000   #\n",
    "# Completo    #    0.98    #   388.753   #   60000   #\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b43ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val, cont = np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "104ff504",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#                     Random                       #\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d225e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para finalizar vamos a estudiar que pasaría al separar los datos de manera aleatoria y no estratificada.\n",
    "# Voy a randomizar el dataset y separarlo en test y train una vez aleatorizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8ab3a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize = np.arange(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f8f36c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ae8dc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 28,28 ))\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "45ef1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains = X_train[randomize]\n",
    "y_trains = y_train[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "faee58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "porc=0.2*len(X_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cc9478ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = int(porc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9273c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainRand = X_trains[0:perc]\n",
    "X_testRand = X_trains[perc:]\n",
    "Y_trainRand = y_trains[0:perc]\n",
    "Y_testRand = y_trains[perc:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d8b24e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_trainRand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d1e6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "val, cont = np.unique(Y_trainRand,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3db6529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2c4f81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "40f4bb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.6102 - accuracy: 0.7844 - val_loss: 0.5099 - val_accuracy: 0.8145\n",
      "Epoch 2/15\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3877 - accuracy: 0.8652 - val_loss: 0.4133 - val_accuracy: 0.8561\n",
      "Epoch 3/15\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3313 - accuracy: 0.8815 - val_loss: 0.3667 - val_accuracy: 0.8722\n",
      "Epoch 4/15\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2879 - accuracy: 0.8977 - val_loss: 0.3390 - val_accuracy: 0.8821\n",
      "Epoch 5/15\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2474 - accuracy: 0.9098 - val_loss: 0.3720 - val_accuracy: 0.8726\n",
      "Epoch 6/15\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2210 - accuracy: 0.9191 - val_loss: 0.3298 - val_accuracy: 0.8847\n",
      "Epoch 7/15\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.1986 - accuracy: 0.9292 - val_loss: 0.3415 - val_accuracy: 0.8860\n",
      "Epoch 8/15\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.1754 - accuracy: 0.9363 - val_loss: 0.3471 - val_accuracy: 0.8855\n",
      "Epoch 9/15\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.1533 - accuracy: 0.9433 - val_loss: 0.3879 - val_accuracy: 0.8780\n",
      "Epoch 10/15\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.1367 - accuracy: 0.9495 - val_loss: 0.3471 - val_accuracy: 0.8900\n",
      "Epoch 11/15\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.1265 - accuracy: 0.9545 - val_loss: 0.3632 - val_accuracy: 0.8868\n",
      "Epoch 12/15\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.1142 - accuracy: 0.9603 - val_loss: 0.3580 - val_accuracy: 0.8911\n",
      "Epoch 13/15\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0947 - accuracy: 0.9669 - val_loss: 0.3906 - val_accuracy: 0.8888\n",
      "Epoch 14/15\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0814 - accuracy: 0.9700 - val_loss: 0.3881 - val_accuracy: 0.8895\n",
      "Epoch 15/15\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0657 - accuracy: 0.9773 - val_loss: 0.3889 - val_accuracy: 0.8897\n"
     ]
    }
   ],
   "source": [
    "inicio=time.time()\n",
    "train = model.fit(X_trainRand, Y_trainRand, epochs=15, batch_size=32,validation_data=(X_testRand, Y_testRand))\n",
    "fin=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "38a20546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.87053394317627"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin-inicio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba85c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#                         CNN                        #\n",
    "######################################################\n",
    "#  Conjunto   #    prec    #   tiempo    #  Muestras #\n",
    "######################################################\n",
    "# Indicador   #    0.88    #   36.9167   # 6000 (5000 + 1000)   #\n",
    "# Estratifi   #    0.88    #   31.705    #    5000   #\n",
    "# Completo    #    0.98    #   388.753   #   60000   #\n",
    "#  Random     #    0.86    #   55.208    #   5000   #\n",
    "######################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
